// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.181.2
//   protoc               v3.21.12
// source: otto.proto

/* eslint-disable */
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  ClientDuplexStream,
  type ClientOptions,
  ClientReadableStream,
  type ClientUnaryCall,
  handleBidiStreamingCall,
  handleServerStreamingCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from '@grpc/grpc-js';
import Long from 'long';
import _m0 from 'protobufjs/minimal';

export const protobufPackage = 'ottoscaler.v1';

/** StageType - Pipeline Stage의 타입을 정의하는 Enum */
export enum StageType {
  /** STAGE_TYPE_UNSPECIFIED - Proto3 관례: 0은 미지정/알 수 없는 타입 */
  STAGE_TYPE_UNSPECIFIED = 0,
  /** STAGE_TYPE_BUILD - 빌드 단계 (컴파일, 패키징 등) */
  STAGE_TYPE_BUILD = 1,
  /** STAGE_TYPE_TEST - 테스트 단계 (단위 테스트, 통합 테스트 등) */
  STAGE_TYPE_TEST = 2,
  /** STAGE_TYPE_DEPLOY - 배포 단계 (스테이징, 프로덕션 배포 등) */
  STAGE_TYPE_DEPLOY = 3,
  /** STAGE_TYPE_SETUP - 환경 설정 단계 (초기화, 의존성 설치 등) */
  STAGE_TYPE_SETUP = 4,
  /** STAGE_TYPE_CLEANUP - 정리 단계 (리소스 정리, 캐시 삭제 등) */
  STAGE_TYPE_CLEANUP = 5,
  /** STAGE_TYPE_NOTIFY - 알림 단계 (이메일, 슬랙 알림 등) */
  STAGE_TYPE_NOTIFY = 6,
  /** STAGE_TYPE_APPROVAL - 승인 대기 단계 (수동 승인 필요) */
  STAGE_TYPE_APPROVAL = 7,
  /** STAGE_TYPE_CUSTOM - 사용자 정의 단계 (위 카테고리에 속하지 않는 경우) */
  STAGE_TYPE_CUSTOM = 100,
  UNRECOGNIZED = -1,
}

/** StageStatus - Pipeline Stage 상태 */
export enum StageStatus {
  /** STAGE_PENDING - 대기 중 */
  STAGE_PENDING = 0,
  /** STAGE_RUNNING - 실행 중 */
  STAGE_RUNNING = 1,
  /** STAGE_COMPLETED - 완료 */
  STAGE_COMPLETED = 2,
  /** STAGE_FAILED - 실패 */
  STAGE_FAILED = 3,
  /** STAGE_CANCELLED - 취소됨 */
  STAGE_CANCELLED = 4,
  /** STAGE_SKIPPED - 건너뜀 (이전 Stage 실패로) */
  STAGE_SKIPPED = 5,
  /** STAGE_RETRYING - 재시도 중 */
  STAGE_RETRYING = 6,
  UNRECOGNIZED = -1,
}

/**
 * LogEntry - Worker Pod에서 생성되는 단일 로그 엔트리
 *
 * 📝 로그 구조 설명:
 * - Worker Pod의 stdout/stderr에서 캐치된 한 줄의 로그를 표현
 * - 시간 정보와 함께 구조화된 형태로 전송
 * - NestJS 서버에서 파싱하여 웹 인터페이스에 실시간 표시
 *
 * 🔍 사용 예시:
 * {
 *   "worker_id": "otto-agent-1-abc123",
 *   "task_id": "task-456",
 *   "timestamp": "2025-09-01T12:34:56.789Z",
 *   "level": "INFO",
 *   "source": "stdout",
 *   "message": "Task processing started...",
 *   "metadata": {"step": "initialization"}
 * }
 */
export interface LogEntry {
  /**
   * Worker Pod의 고유 식별자 (예: "otto-agent-1-abc123")
   * Main Pod에서 생성한 Worker Pod의 이름과 일치해야 함
   */
  workerId: string;
  /**
   * Redis 이벤트에서 온 작업 식별자 (예: "task-456")
   * 어떤 scale_up 이벤트로 인해 생성된 작업인지 추적
   */
  taskId: string;
  /**
   * 로그 생성 시간 (RFC3339 형식: "2025-09-01T12:34:56.789Z")
   * Worker Pod 내부에서 로그가 실제로 발생한 시점
   */
  timestamp: string;
  /**
   * 로그 레벨 (INFO, ERROR, DEBUG, WARN 등)
   * 로그의 중요도나 유형을 나타냄
   */
  level: string;
  /**
   * 로그 소스 (stdout, stderr)
   * 표준 출력인지 에러 출력인지 구분
   */
  source: string;
  /**
   * 실제 로그 메시지 내용 (cmd창에 출력되는 한 줄)
   * Worker Pod의 작업 진행 상황, 에러, 디버그 정보 등
   */
  message: string;
  /**
   * 추가 메타데이터 (선택적)
   * 작업 단계, 파일명, 함수명 등 부가 정보
   */
  metadata: { [key: string]: string };
}

export interface LogEntry_MetadataEntry {
  key: string;
  value: string;
}

/**
 * LogResponse - NestJS 서버에서 Worker Pod로의 응답 메시지
 *
 * 🔄 응답 처리 로직:
 * - ACK: 로그 성공적으로 받음, 다음 로그 전송 가능
 * - RETRY: 일시적 실패, 같은 로그를 다시 전송 필요
 * - DROP: 영구적 실패, 해당 로그 포기하고 다음으로 진행
 *
 * 📊 백프레셔(Backpressure) 처리:
 * - 서버 과부하 시 RETRY 응답으로 Worker Pod 전송 속도 조절
 * - sequence 번호로 로그 순서 보장
 */
export interface LogResponse {
  /** 로그 처리 결과 상태 */
  status: LogResponse_Status;
  /**
   * 디버깅용 메시지 (선택적)
   * 에러 이유나 추가 정보 제공
   */
  message: string;
  /**
   * 순서 보장을 위한 시퀀스 번호 (선택적)
   * 로그 전송 순서와 처리 순서 매칭
   */
  sequence: number;
}

/**
 * Status - 로그 처리 결과 상태
 *
 * ✅ ACK (0): 성공적으로 처리됨
 * 🔄 RETRY (1): 일시적 오류, 재시도 필요 (네트워크 지연, 서버 부하 등)
 * ❌ DROP (2): 영구적 오류, 해당 로그 포기 (잘못된 형식, 권한 없음 등)
 */
export enum LogResponse_Status {
  /** ACK - 성공적으로 받고 처리함 */
  ACK = 0,
  /** RETRY - 일시적 실패, 재시도 요청 */
  RETRY = 1,
  /** DROP - 영구적 실패, 로그 포기 */
  DROP = 2,
  UNRECOGNIZED = -1,
}

/** WorkerRegistration contains information about a starting worker */
export interface WorkerRegistration {
  /** Worker pod identifier */
  workerId: string;
  /** Task identifier this worker is handling */
  taskId: string;
  /** Worker pod metadata */
  metadata: WorkerMetadata | undefined;
  /** NestJS server endpoint (for health checks) */
  serverEndpoint: string;
}

/** WorkerMetadata contains Kubernetes pod information */
export interface WorkerMetadata {
  /** Pod name in Kubernetes */
  podName: string;
  /** Kubernetes namespace */
  namespace: string;
  /** Node where pod is running */
  nodeName: string;
  /** Pod creation timestamp */
  createdAt: string;
  /** Labels applied to the pod */
  labels: { [key: string]: string };
}

export interface WorkerMetadata_LabelsEntry {
  key: string;
  value: string;
}

/** RegistrationResponse confirms worker registration */
export interface RegistrationResponse {
  status: RegistrationResponse_Status;
  message: string;
  /** Server-assigned session ID for this worker */
  sessionId: string;
  /** Recommended logging configuration */
  config: LoggingConfig | undefined;
}

export enum RegistrationResponse_Status {
  SUCCESS = 0,
  ALREADY_REGISTERED = 1,
  SERVER_FULL = 2,
  INVALID_REQUEST = 3,
  UNRECOGNIZED = -1,
}

/** LoggingConfig contains server preferences for logging */
export interface LoggingConfig {
  /** Maximum logs per second from this worker */
  rateLimit: number;
  /** Buffer size for batching logs */
  bufferSize: number;
  /** Maximum message size in bytes */
  maxMessageSize: number;
  /** Whether to include full metadata */
  includeMetadata: boolean;
}

/** ScaleRequest - 스케일링 요청 메시지 */
export interface ScaleRequest {
  /** 작업 고유 식별자 (CI/CD 작업 ID) */
  taskId: string;
  /** Git 저장소 URL */
  repository: string;
  /** Git 커밋 SHA */
  commitSha: string;
  /** 스케일링할 Worker Pod 수 (scale_up 시 생성할 수, scale_down 시 목표 수) */
  workerCount: number;
  /** CI/CD 빌드 설정 (환경 변수, 명령어 등) */
  buildConfig: { [key: string]: string };
  /** 요청을 시작한 주체 (사용자 또는 시스템) */
  triggeredBy: string;
  /** 스케일링 요청 사유 */
  reason: string;
  /** 추가 메타데이터 */
  metadata: { [key: string]: string };
}

export interface ScaleRequest_BuildConfigEntry {
  key: string;
  value: string;
}

export interface ScaleRequest_MetadataEntry {
  key: string;
  value: string;
}

/** ScaleResponse - 스케일링 응답 메시지 */
export interface ScaleResponse {
  /** 응답 상태 */
  status: ScaleResponse_Status;
  /** 응답 메시지 (에러 정보 또는 성공 메시지) */
  message: string;
  /** 실제로 처리된 Worker Pod 수 */
  processedCount: number;
  /** 생성/삭제된 Worker Pod 목록 */
  workerPodNames: string[];
  /** 처리 시작 시간 (RFC3339 형식) */
  startedAt: string;
  /** 처리 완료 시간 (RFC3339 형식) */
  completedAt: string;
}

export enum ScaleResponse_Status {
  /** SUCCESS - 성공 */
  SUCCESS = 0,
  /** FAILED - 실패 */
  FAILED = 1,
  /** PARTIAL_SUCCESS - 부분 성공 (일부 Pod만 처리됨) */
  PARTIAL_SUCCESS = 2,
  /** ALREADY_PROCESSED - 이미 처리된 요청 */
  ALREADY_PROCESSED = 3,
  UNRECOGNIZED = -1,
}

/** WorkerStatusRequest - Worker 상태 조회 요청 */
export interface WorkerStatusRequest {
  /** 특정 작업 ID로 필터링 (비어있으면 전체 조회) */
  taskId: string;
  /** 특정 Worker Pod 이름으로 필터링 */
  workerPodName: string;
  /** 상태로 필터링 ("running", "pending", "succeeded", "failed") */
  statusFilter: string;
}

/** WorkerStatusResponse - Worker 상태 조회 응답 */
export interface WorkerStatusResponse {
  /** 전체 Worker Pod 수 */
  totalCount: number;
  /** 상태별 Worker Pod 수 */
  runningCount: number;
  pendingCount: number;
  succeededCount: number;
  failedCount: number;
  /** Worker Pod 상세 정보 목록 */
  workers: WorkerPodStatus[];
}

/** WorkerPodStatus - 개별 Worker Pod 상태 정보 */
export interface WorkerPodStatus {
  /** Pod 이름 */
  podName: string;
  /** 작업 ID */
  taskId: string;
  /** Pod 상태 ("pending", "running", "succeeded", "failed") */
  status: string;
  /** Pod 생성 시간 */
  createdAt: string;
  /** Pod 시작 시간 */
  startedAt: string;
  /** Pod 완료 시간 (완료된 경우) */
  completedAt: string;
  /** 실행 중인 노드 */
  nodeName: string;
  /** Pod IP */
  podIp: string;
  /** 추가 라벨 */
  labels: { [key: string]: string };
  /** 에러 메시지 (실패한 경우) */
  errorMessage: string;
}

export interface WorkerPodStatus_LabelsEntry {
  key: string;
  value: string;
}

/** WorkerLogEntry - Ottoscaler에서 Otto-handler로 전달하는 Worker 로그 엔트리 */
export interface WorkerLogEntry {
  /** Worker Pod의 고유 식별자 */
  workerId: string;
  /** 작업 식별자 (CI/CD 작업 ID) */
  taskId: string;
  /** 로그 생성 시간 (RFC3339 형식) */
  timestamp: string;
  /** 로그 레벨 (INFO, ERROR, DEBUG, WARN) */
  level: string;
  /** 로그 소스 (stdout, stderr) */
  source: string;
  /** 실제 로그 메시지 내용 */
  message: string;
  /** Pod 관련 메타데이터 */
  podMetadata: WorkerMetadata | undefined;
  /** 추가 메타데이터 */
  metadata: { [key: string]: string };
}

export interface WorkerLogEntry_MetadataEntry {
  key: string;
  value: string;
}

/** LogForwardResponse - Otto-handler에서 Ottoscaler로의 로그 처리 응답 */
export interface LogForwardResponse {
  /** 로그 처리 결과 상태 */
  status: LogForwardResponse_Status;
  /** 응답 메시지 (에러 정보 또는 성공 메시지) */
  message: string;
  /** 순서 보장을 위한 시퀀스 번호 */
  sequence: number;
  /** 백프레셔 제어: 다음 로그까지 대기 시간 (ms) */
  throttleMs: number;
}

export enum LogForwardResponse_Status {
  /** ACK - 성공적으로 받고 처리함 */
  ACK = 0,
  /** RETRY - 일시적 실패, 재시도 요청 */
  RETRY = 1,
  /** DROP - 영구적 실패, 로그 포기 */
  DROP = 2,
  UNRECOGNIZED = -1,
}

/** WorkerStatusNotification - Worker Pod 상태 변경 알림 */
export interface WorkerStatusNotification {
  /** Worker Pod 이름 */
  workerId: string;
  /** 작업 ID */
  taskId: string;
  /** 상태 타입 */
  status: WorkerStatusNotification_StatusType;
  /** 상태 변경 시간 */
  timestamp: string;
  /** 상태 변경 이유/메시지 */
  reason: string;
  /** 추가 메타데이터 */
  metadata: { [key: string]: string };
}

export enum WorkerStatusNotification_StatusType {
  /** CREATED - Pod 생성됨 */
  CREATED = 0,
  /** RUNNING - Pod 실행 중 */
  RUNNING = 1,
  /** COMPLETED - Pod 성공 완료 */
  COMPLETED = 2,
  /** FAILED - Pod 실패 */
  FAILED = 3,
  /** TERMINATED - Pod 강제 종료 */
  TERMINATED = 4,
  UNRECOGNIZED = -1,
}

export interface WorkerStatusNotification_MetadataEntry {
  key: string;
  value: string;
}

/** WorkerStatusAck - Worker 상태 알림에 대한 응답 */
export interface WorkerStatusAck {
  status: WorkerStatusAck_Status;
  message: string;
}

export enum WorkerStatusAck_Status {
  /** RECEIVED - 성공적으로 받음 */
  RECEIVED = 0,
  /** IGNORED - 무시됨 (중복 등) */
  IGNORED = 1,
  /** ERROR - 처리 중 에러 */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

/** PipelineRequest - Pipeline 실행 요청 */
export interface PipelineRequest {
  /** Pipeline 고유 ID */
  pipelineId: string;
  /** Pipeline 이름 (예: "Full CI/CD", "Build and Test") */
  name: string;
  /** Pipeline을 구성하는 Stage들 */
  stages: PipelineStage[];
  /** Repository 정보 */
  repository: string;
  /** Commit SHA */
  commitSha: string;
  /** 트리거한 사용자/시스템 */
  triggeredBy: string;
  /** Pipeline 메타데이터 */
  metadata: { [key: string]: string };
}

export interface PipelineRequest_MetadataEntry {
  key: string;
  value: string;
}

/** PipelineStage - Pipeline을 구성하는 개별 Stage */
export interface PipelineStage {
  /** Stage ID (예: "build", "unit-test", "deploy-staging") */
  stageId: string;
  /** Stage 타입 (Enum으로 타입 안정성 보장) */
  type: StageType;
  /** Stage 이름 */
  name: string;
  /** 이 Stage를 위한 Worker 수 */
  workerCount: number;
  /** 의존하는 Stage ID 목록 (병렬 실행 가능 판단용) */
  dependsOn: string[];
  /** Stage별 설정 (환경변수, 파라미터 등) */
  config: { [key: string]: string };
  /** 사용할 이미지 (비어있으면 기본 이미지 사용) */
  image: string;
  /** 실행할 명령어 */
  command: string[];
  /** 명령어 인자 */
  args: string[];
  /** 타임아웃 (초 단위, 0이면 무제한) */
  timeoutSeconds: number;
  /** 재시도 정책 */
  retryPolicy: RetryPolicy | undefined;
}

export interface PipelineStage_ConfigEntry {
  key: string;
  value: string;
}

/** RetryPolicy - Stage 실패 시 재시도 정책 */
export interface RetryPolicy {
  /** 최대 재시도 횟수 */
  maxAttempts: number;
  /** 재시도 간격 (초) */
  retryDelaySeconds: number;
  /** 재시도 가능한 실패 유형 */
  retryableFailures: string[];
}

/** PipelineProgress - Pipeline 실행 진행 상황 */
export interface PipelineProgress {
  /** Pipeline ID */
  pipelineId: string;
  /** 현재 Stage ID */
  stageId: string;
  /** Stage 상태 */
  status: StageStatus;
  /** 상태 메시지 */
  message: string;
  /** 이 Stage를 위해 생성된 Worker Pod 이름들 */
  workerPodNames: string[];
  /** 진행률 (0-100) */
  progressPercentage: number;
  /** 타임스탬프 */
  timestamp: string;
  /** Stage 시작 시간 */
  startedAt: string;
  /** Stage 완료 시간 (완료된 경우) */
  completedAt: string;
  /** 에러 정보 (실패한 경우) */
  errorMessage: string;
  /** Stage 메트릭 */
  metrics: StageMetrics | undefined;
}

/** StageMetrics - Stage 실행 메트릭 */
export interface StageMetrics {
  /** 실행 시간 (초) */
  durationSeconds: number;
  /** 성공한 Worker 수 */
  successfulWorkers: number;
  /** 실패한 Worker 수 */
  failedWorkers: number;
  /** 총 Worker 수 */
  totalWorkers: number;
  /** CPU 사용량 (평균) */
  avgCpuUsage: number;
  /** 메모리 사용량 (평균, MB) */
  avgMemoryMb: number;
}

function createBaseLogEntry(): LogEntry {
  return {
    workerId: '',
    taskId: '',
    timestamp: '',
    level: '',
    source: '',
    message: '',
    metadata: {},
  };
}

export const LogEntry = {
  encode(
    message: LogEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.workerId !== '') {
      writer.uint32(10).string(message.workerId);
    }
    if (message.taskId !== '') {
      writer.uint32(18).string(message.taskId);
    }
    if (message.timestamp !== '') {
      writer.uint32(26).string(message.timestamp);
    }
    if (message.level !== '') {
      writer.uint32(34).string(message.level);
    }
    if (message.source !== '') {
      writer.uint32(42).string(message.source);
    }
    if (message.message !== '') {
      writer.uint32(50).string(message.message);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      LogEntry_MetadataEntry.encode(
        { key: key as any, value },
        writer.uint32(58).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): LogEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLogEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.level = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.source = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.message = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = LogEntry_MetadataEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.metadata[entry7.key] = entry7.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<LogEntry>): LogEntry {
    return LogEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LogEntry>): LogEntry {
    const message = createBaseLogEntry();
    message.workerId = object.workerId ?? '';
    message.taskId = object.taskId ?? '';
    message.timestamp = object.timestamp ?? '';
    message.level = object.level ?? '';
    message.source = object.source ?? '';
    message.message = object.message ?? '';
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseLogEntry_MetadataEntry(): LogEntry_MetadataEntry {
  return { key: '', value: '' };
}

export const LogEntry_MetadataEntry = {
  encode(
    message: LogEntry_MetadataEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): LogEntry_MetadataEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLogEntry_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<LogEntry_MetadataEntry>): LogEntry_MetadataEntry {
    return LogEntry_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<LogEntry_MetadataEntry>,
  ): LogEntry_MetadataEntry {
    const message = createBaseLogEntry_MetadataEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseLogResponse(): LogResponse {
  return { status: 0, message: '', sequence: 0 };
}

export const LogResponse = {
  encode(
    message: LogResponse,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(18).string(message.message);
    }
    if (message.sequence !== 0) {
      writer.uint32(24).int64(message.sequence);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): LogResponse {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLogResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.sequence = longToNumber(reader.int64() as Long);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<LogResponse>): LogResponse {
    return LogResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LogResponse>): LogResponse {
    const message = createBaseLogResponse();
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    message.sequence = object.sequence ?? 0;
    return message;
  },
};

function createBaseWorkerRegistration(): WorkerRegistration {
  return { workerId: '', taskId: '', metadata: undefined, serverEndpoint: '' };
}

export const WorkerRegistration = {
  encode(
    message: WorkerRegistration,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.workerId !== '') {
      writer.uint32(10).string(message.workerId);
    }
    if (message.taskId !== '') {
      writer.uint32(18).string(message.taskId);
    }
    if (message.metadata !== undefined) {
      WorkerMetadata.encode(
        message.metadata,
        writer.uint32(26).fork(),
      ).ldelim();
    }
    if (message.serverEndpoint !== '') {
      writer.uint32(34).string(message.serverEndpoint);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerRegistration {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerRegistration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.metadata = WorkerMetadata.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serverEndpoint = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerRegistration>): WorkerRegistration {
    return WorkerRegistration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerRegistration>): WorkerRegistration {
    const message = createBaseWorkerRegistration();
    message.workerId = object.workerId ?? '';
    message.taskId = object.taskId ?? '';
    message.metadata =
      object.metadata !== undefined && object.metadata !== null
        ? WorkerMetadata.fromPartial(object.metadata)
        : undefined;
    message.serverEndpoint = object.serverEndpoint ?? '';
    return message;
  },
};

function createBaseWorkerMetadata(): WorkerMetadata {
  return {
    podName: '',
    namespace: '',
    nodeName: '',
    createdAt: '',
    labels: {},
  };
}

export const WorkerMetadata = {
  encode(
    message: WorkerMetadata,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.podName !== '') {
      writer.uint32(10).string(message.podName);
    }
    if (message.namespace !== '') {
      writer.uint32(18).string(message.namespace);
    }
    if (message.nodeName !== '') {
      writer.uint32(26).string(message.nodeName);
    }
    if (message.createdAt !== '') {
      writer.uint32(34).string(message.createdAt);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      WorkerMetadata_LabelsEntry.encode(
        { key: key as any, value },
        writer.uint32(42).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerMetadata {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.podName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.namespace = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nodeName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createdAt = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = WorkerMetadata_LabelsEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerMetadata>): WorkerMetadata {
    return WorkerMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerMetadata>): WorkerMetadata {
    const message = createBaseWorkerMetadata();
    message.podName = object.podName ?? '';
    message.namespace = object.namespace ?? '';
    message.nodeName = object.nodeName ?? '';
    message.createdAt = object.createdAt ?? '';
    message.labels = Object.entries(object.labels ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseWorkerMetadata_LabelsEntry(): WorkerMetadata_LabelsEntry {
  return { key: '', value: '' };
}

export const WorkerMetadata_LabelsEntry = {
  encode(
    message: WorkerMetadata_LabelsEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerMetadata_LabelsEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerMetadata_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<WorkerMetadata_LabelsEntry>,
  ): WorkerMetadata_LabelsEntry {
    return WorkerMetadata_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WorkerMetadata_LabelsEntry>,
  ): WorkerMetadata_LabelsEntry {
    const message = createBaseWorkerMetadata_LabelsEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseRegistrationResponse(): RegistrationResponse {
  return { status: 0, message: '', sessionId: '', config: undefined };
}

export const RegistrationResponse = {
  encode(
    message: RegistrationResponse,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(18).string(message.message);
    }
    if (message.sessionId !== '') {
      writer.uint32(26).string(message.sessionId);
    }
    if (message.config !== undefined) {
      LoggingConfig.encode(message.config, writer.uint32(34).fork()).ldelim();
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): RegistrationResponse {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRegistrationResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sessionId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.config = LoggingConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<RegistrationResponse>): RegistrationResponse {
    return RegistrationResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RegistrationResponse>): RegistrationResponse {
    const message = createBaseRegistrationResponse();
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    message.sessionId = object.sessionId ?? '';
    message.config =
      object.config !== undefined && object.config !== null
        ? LoggingConfig.fromPartial(object.config)
        : undefined;
    return message;
  },
};

function createBaseLoggingConfig(): LoggingConfig {
  return {
    rateLimit: 0,
    bufferSize: 0,
    maxMessageSize: 0,
    includeMetadata: false,
  };
}

export const LoggingConfig = {
  encode(
    message: LoggingConfig,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.rateLimit !== 0) {
      writer.uint32(8).int32(message.rateLimit);
    }
    if (message.bufferSize !== 0) {
      writer.uint32(16).int32(message.bufferSize);
    }
    if (message.maxMessageSize !== 0) {
      writer.uint32(24).int32(message.maxMessageSize);
    }
    if (message.includeMetadata !== false) {
      writer.uint32(32).bool(message.includeMetadata);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): LoggingConfig {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLoggingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rateLimit = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.bufferSize = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.maxMessageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.includeMetadata = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<LoggingConfig>): LoggingConfig {
    return LoggingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LoggingConfig>): LoggingConfig {
    const message = createBaseLoggingConfig();
    message.rateLimit = object.rateLimit ?? 0;
    message.bufferSize = object.bufferSize ?? 0;
    message.maxMessageSize = object.maxMessageSize ?? 0;
    message.includeMetadata = object.includeMetadata ?? false;
    return message;
  },
};

function createBaseScaleRequest(): ScaleRequest {
  return {
    taskId: '',
    repository: '',
    commitSha: '',
    workerCount: 0,
    buildConfig: {},
    triggeredBy: '',
    reason: '',
    metadata: {},
  };
}

export const ScaleRequest = {
  encode(
    message: ScaleRequest,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.taskId !== '') {
      writer.uint32(10).string(message.taskId);
    }
    if (message.repository !== '') {
      writer.uint32(18).string(message.repository);
    }
    if (message.commitSha !== '') {
      writer.uint32(26).string(message.commitSha);
    }
    if (message.workerCount !== 0) {
      writer.uint32(32).int32(message.workerCount);
    }
    Object.entries(message.buildConfig).forEach(([key, value]) => {
      ScaleRequest_BuildConfigEntry.encode(
        { key: key as any, value },
        writer.uint32(42).fork(),
      ).ldelim();
    });
    if (message.triggeredBy !== '') {
      writer.uint32(50).string(message.triggeredBy);
    }
    if (message.reason !== '') {
      writer.uint32(58).string(message.reason);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      ScaleRequest_MetadataEntry.encode(
        { key: key as any, value },
        writer.uint32(66).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ScaleRequest {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.workerCount = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = ScaleRequest_BuildConfigEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry5.value !== undefined) {
            message.buildConfig[entry5.key] = entry5.value;
          }
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.triggeredBy = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.reason = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = ScaleRequest_MetadataEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry8.value !== undefined) {
            message.metadata[entry8.key] = entry8.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<ScaleRequest>): ScaleRequest {
    return ScaleRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ScaleRequest>): ScaleRequest {
    const message = createBaseScaleRequest();
    message.taskId = object.taskId ?? '';
    message.repository = object.repository ?? '';
    message.commitSha = object.commitSha ?? '';
    message.workerCount = object.workerCount ?? 0;
    message.buildConfig = Object.entries(object.buildConfig ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.triggeredBy = object.triggeredBy ?? '';
    message.reason = object.reason ?? '';
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseScaleRequest_BuildConfigEntry(): ScaleRequest_BuildConfigEntry {
  return { key: '', value: '' };
}

export const ScaleRequest_BuildConfigEntry = {
  encode(
    message: ScaleRequest_BuildConfigEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): ScaleRequest_BuildConfigEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleRequest_BuildConfigEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<ScaleRequest_BuildConfigEntry>,
  ): ScaleRequest_BuildConfigEntry {
    return ScaleRequest_BuildConfigEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ScaleRequest_BuildConfigEntry>,
  ): ScaleRequest_BuildConfigEntry {
    const message = createBaseScaleRequest_BuildConfigEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseScaleRequest_MetadataEntry(): ScaleRequest_MetadataEntry {
  return { key: '', value: '' };
}

export const ScaleRequest_MetadataEntry = {
  encode(
    message: ScaleRequest_MetadataEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): ScaleRequest_MetadataEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleRequest_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<ScaleRequest_MetadataEntry>,
  ): ScaleRequest_MetadataEntry {
    return ScaleRequest_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ScaleRequest_MetadataEntry>,
  ): ScaleRequest_MetadataEntry {
    const message = createBaseScaleRequest_MetadataEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseScaleResponse(): ScaleResponse {
  return {
    status: 0,
    message: '',
    processedCount: 0,
    workerPodNames: [],
    startedAt: '',
    completedAt: '',
  };
}

export const ScaleResponse = {
  encode(
    message: ScaleResponse,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(18).string(message.message);
    }
    if (message.processedCount !== 0) {
      writer.uint32(24).int32(message.processedCount);
    }
    for (const v of message.workerPodNames) {
      writer.uint32(34).string(v!);
    }
    if (message.startedAt !== '') {
      writer.uint32(42).string(message.startedAt);
    }
    if (message.completedAt !== '') {
      writer.uint32(50).string(message.completedAt);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ScaleResponse {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.processedCount = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.workerPodNames.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.startedAt = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.completedAt = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<ScaleResponse>): ScaleResponse {
    return ScaleResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ScaleResponse>): ScaleResponse {
    const message = createBaseScaleResponse();
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    message.processedCount = object.processedCount ?? 0;
    message.workerPodNames = object.workerPodNames?.map((e) => e) || [];
    message.startedAt = object.startedAt ?? '';
    message.completedAt = object.completedAt ?? '';
    return message;
  },
};

function createBaseWorkerStatusRequest(): WorkerStatusRequest {
  return { taskId: '', workerPodName: '', statusFilter: '' };
}

export const WorkerStatusRequest = {
  encode(
    message: WorkerStatusRequest,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.taskId !== '') {
      writer.uint32(10).string(message.taskId);
    }
    if (message.workerPodName !== '') {
      writer.uint32(18).string(message.workerPodName);
    }
    if (message.statusFilter !== '') {
      writer.uint32(26).string(message.statusFilter);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerStatusRequest {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerStatusRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workerPodName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.statusFilter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerStatusRequest>): WorkerStatusRequest {
    return WorkerStatusRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerStatusRequest>): WorkerStatusRequest {
    const message = createBaseWorkerStatusRequest();
    message.taskId = object.taskId ?? '';
    message.workerPodName = object.workerPodName ?? '';
    message.statusFilter = object.statusFilter ?? '';
    return message;
  },
};

function createBaseWorkerStatusResponse(): WorkerStatusResponse {
  return {
    totalCount: 0,
    runningCount: 0,
    pendingCount: 0,
    succeededCount: 0,
    failedCount: 0,
    workers: [],
  };
}

export const WorkerStatusResponse = {
  encode(
    message: WorkerStatusResponse,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.totalCount !== 0) {
      writer.uint32(8).int32(message.totalCount);
    }
    if (message.runningCount !== 0) {
      writer.uint32(16).int32(message.runningCount);
    }
    if (message.pendingCount !== 0) {
      writer.uint32(24).int32(message.pendingCount);
    }
    if (message.succeededCount !== 0) {
      writer.uint32(32).int32(message.succeededCount);
    }
    if (message.failedCount !== 0) {
      writer.uint32(40).int32(message.failedCount);
    }
    for (const v of message.workers) {
      WorkerPodStatus.encode(v!, writer.uint32(50).fork()).ldelim();
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerStatusResponse {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerStatusResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.totalCount = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.runningCount = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pendingCount = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.succeededCount = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.failedCount = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.workers.push(WorkerPodStatus.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerStatusResponse>): WorkerStatusResponse {
    return WorkerStatusResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerStatusResponse>): WorkerStatusResponse {
    const message = createBaseWorkerStatusResponse();
    message.totalCount = object.totalCount ?? 0;
    message.runningCount = object.runningCount ?? 0;
    message.pendingCount = object.pendingCount ?? 0;
    message.succeededCount = object.succeededCount ?? 0;
    message.failedCount = object.failedCount ?? 0;
    message.workers =
      object.workers?.map((e) => WorkerPodStatus.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWorkerPodStatus(): WorkerPodStatus {
  return {
    podName: '',
    taskId: '',
    status: '',
    createdAt: '',
    startedAt: '',
    completedAt: '',
    nodeName: '',
    podIp: '',
    labels: {},
    errorMessage: '',
  };
}

export const WorkerPodStatus = {
  encode(
    message: WorkerPodStatus,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.podName !== '') {
      writer.uint32(10).string(message.podName);
    }
    if (message.taskId !== '') {
      writer.uint32(18).string(message.taskId);
    }
    if (message.status !== '') {
      writer.uint32(26).string(message.status);
    }
    if (message.createdAt !== '') {
      writer.uint32(34).string(message.createdAt);
    }
    if (message.startedAt !== '') {
      writer.uint32(42).string(message.startedAt);
    }
    if (message.completedAt !== '') {
      writer.uint32(50).string(message.completedAt);
    }
    if (message.nodeName !== '') {
      writer.uint32(58).string(message.nodeName);
    }
    if (message.podIp !== '') {
      writer.uint32(66).string(message.podIp);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      WorkerPodStatus_LabelsEntry.encode(
        { key: key as any, value },
        writer.uint32(74).fork(),
      ).ldelim();
    });
    if (message.errorMessage !== '') {
      writer.uint32(82).string(message.errorMessage);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerPodStatus {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerPodStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.podName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.status = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createdAt = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.startedAt = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.completedAt = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.nodeName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.podIp = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          const entry9 = WorkerPodStatus_LabelsEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerPodStatus>): WorkerPodStatus {
    return WorkerPodStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerPodStatus>): WorkerPodStatus {
    const message = createBaseWorkerPodStatus();
    message.podName = object.podName ?? '';
    message.taskId = object.taskId ?? '';
    message.status = object.status ?? '';
    message.createdAt = object.createdAt ?? '';
    message.startedAt = object.startedAt ?? '';
    message.completedAt = object.completedAt ?? '';
    message.nodeName = object.nodeName ?? '';
    message.podIp = object.podIp ?? '';
    message.labels = Object.entries(object.labels ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.errorMessage = object.errorMessage ?? '';
    return message;
  },
};

function createBaseWorkerPodStatus_LabelsEntry(): WorkerPodStatus_LabelsEntry {
  return { key: '', value: '' };
}

export const WorkerPodStatus_LabelsEntry = {
  encode(
    message: WorkerPodStatus_LabelsEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerPodStatus_LabelsEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerPodStatus_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<WorkerPodStatus_LabelsEntry>,
  ): WorkerPodStatus_LabelsEntry {
    return WorkerPodStatus_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WorkerPodStatus_LabelsEntry>,
  ): WorkerPodStatus_LabelsEntry {
    const message = createBaseWorkerPodStatus_LabelsEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseWorkerLogEntry(): WorkerLogEntry {
  return {
    workerId: '',
    taskId: '',
    timestamp: '',
    level: '',
    source: '',
    message: '',
    podMetadata: undefined,
    metadata: {},
  };
}

export const WorkerLogEntry = {
  encode(
    message: WorkerLogEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.workerId !== '') {
      writer.uint32(10).string(message.workerId);
    }
    if (message.taskId !== '') {
      writer.uint32(18).string(message.taskId);
    }
    if (message.timestamp !== '') {
      writer.uint32(26).string(message.timestamp);
    }
    if (message.level !== '') {
      writer.uint32(34).string(message.level);
    }
    if (message.source !== '') {
      writer.uint32(42).string(message.source);
    }
    if (message.message !== '') {
      writer.uint32(50).string(message.message);
    }
    if (message.podMetadata !== undefined) {
      WorkerMetadata.encode(
        message.podMetadata,
        writer.uint32(58).fork(),
      ).ldelim();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      WorkerLogEntry_MetadataEntry.encode(
        { key: key as any, value },
        writer.uint32(66).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerLogEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerLogEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.level = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.source = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.message = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.podMetadata = WorkerMetadata.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = WorkerLogEntry_MetadataEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry8.value !== undefined) {
            message.metadata[entry8.key] = entry8.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerLogEntry>): WorkerLogEntry {
    return WorkerLogEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerLogEntry>): WorkerLogEntry {
    const message = createBaseWorkerLogEntry();
    message.workerId = object.workerId ?? '';
    message.taskId = object.taskId ?? '';
    message.timestamp = object.timestamp ?? '';
    message.level = object.level ?? '';
    message.source = object.source ?? '';
    message.message = object.message ?? '';
    message.podMetadata =
      object.podMetadata !== undefined && object.podMetadata !== null
        ? WorkerMetadata.fromPartial(object.podMetadata)
        : undefined;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseWorkerLogEntry_MetadataEntry(): WorkerLogEntry_MetadataEntry {
  return { key: '', value: '' };
}

export const WorkerLogEntry_MetadataEntry = {
  encode(
    message: WorkerLogEntry_MetadataEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerLogEntry_MetadataEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerLogEntry_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<WorkerLogEntry_MetadataEntry>,
  ): WorkerLogEntry_MetadataEntry {
    return WorkerLogEntry_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WorkerLogEntry_MetadataEntry>,
  ): WorkerLogEntry_MetadataEntry {
    const message = createBaseWorkerLogEntry_MetadataEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseLogForwardResponse(): LogForwardResponse {
  return { status: 0, message: '', sequence: 0, throttleMs: 0 };
}

export const LogForwardResponse = {
  encode(
    message: LogForwardResponse,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(18).string(message.message);
    }
    if (message.sequence !== 0) {
      writer.uint32(24).int64(message.sequence);
    }
    if (message.throttleMs !== 0) {
      writer.uint32(32).int32(message.throttleMs);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): LogForwardResponse {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLogForwardResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.sequence = longToNumber(reader.int64() as Long);
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.throttleMs = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<LogForwardResponse>): LogForwardResponse {
    return LogForwardResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LogForwardResponse>): LogForwardResponse {
    const message = createBaseLogForwardResponse();
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    message.sequence = object.sequence ?? 0;
    message.throttleMs = object.throttleMs ?? 0;
    return message;
  },
};

function createBaseWorkerStatusNotification(): WorkerStatusNotification {
  return {
    workerId: '',
    taskId: '',
    status: 0,
    timestamp: '',
    reason: '',
    metadata: {},
  };
}

export const WorkerStatusNotification = {
  encode(
    message: WorkerStatusNotification,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.workerId !== '') {
      writer.uint32(10).string(message.workerId);
    }
    if (message.taskId !== '') {
      writer.uint32(18).string(message.taskId);
    }
    if (message.status !== 0) {
      writer.uint32(24).int32(message.status);
    }
    if (message.timestamp !== '') {
      writer.uint32(34).string(message.timestamp);
    }
    if (message.reason !== '') {
      writer.uint32(42).string(message.reason);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      WorkerStatusNotification_MetadataEntry.encode(
        { key: key as any, value },
        writer.uint32(50).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerStatusNotification {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerStatusNotification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.taskId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timestamp = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.reason = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = WorkerStatusNotification_MetadataEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry6.value !== undefined) {
            message.metadata[entry6.key] = entry6.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<WorkerStatusNotification>,
  ): WorkerStatusNotification {
    return WorkerStatusNotification.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WorkerStatusNotification>,
  ): WorkerStatusNotification {
    const message = createBaseWorkerStatusNotification();
    message.workerId = object.workerId ?? '';
    message.taskId = object.taskId ?? '';
    message.status = object.status ?? 0;
    message.timestamp = object.timestamp ?? '';
    message.reason = object.reason ?? '';
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseWorkerStatusNotification_MetadataEntry(): WorkerStatusNotification_MetadataEntry {
  return { key: '', value: '' };
}

export const WorkerStatusNotification_MetadataEntry = {
  encode(
    message: WorkerStatusNotification_MetadataEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): WorkerStatusNotification_MetadataEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerStatusNotification_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<WorkerStatusNotification_MetadataEntry>,
  ): WorkerStatusNotification_MetadataEntry {
    return WorkerStatusNotification_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WorkerStatusNotification_MetadataEntry>,
  ): WorkerStatusNotification_MetadataEntry {
    const message = createBaseWorkerStatusNotification_MetadataEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseWorkerStatusAck(): WorkerStatusAck {
  return { status: 0, message: '' };
}

export const WorkerStatusAck = {
  encode(
    message: WorkerStatusAck,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(18).string(message.message);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WorkerStatusAck {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerStatusAck();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<WorkerStatusAck>): WorkerStatusAck {
    return WorkerStatusAck.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerStatusAck>): WorkerStatusAck {
    const message = createBaseWorkerStatusAck();
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    return message;
  },
};

function createBasePipelineRequest(): PipelineRequest {
  return {
    pipelineId: '',
    name: '',
    stages: [],
    repository: '',
    commitSha: '',
    triggeredBy: '',
    metadata: {},
  };
}

export const PipelineRequest = {
  encode(
    message: PipelineRequest,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.pipelineId !== '') {
      writer.uint32(10).string(message.pipelineId);
    }
    if (message.name !== '') {
      writer.uint32(18).string(message.name);
    }
    for (const v of message.stages) {
      PipelineStage.encode(v!, writer.uint32(26).fork()).ldelim();
    }
    if (message.repository !== '') {
      writer.uint32(34).string(message.repository);
    }
    if (message.commitSha !== '') {
      writer.uint32(42).string(message.commitSha);
    }
    if (message.triggeredBy !== '') {
      writer.uint32(50).string(message.triggeredBy);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      PipelineRequest_MetadataEntry.encode(
        { key: key as any, value },
        writer.uint32(58).fork(),
      ).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): PipelineRequest {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipelineId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.stages.push(PipelineStage.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.triggeredBy = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = PipelineRequest_MetadataEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry7.value !== undefined) {
            message.metadata[entry7.key] = entry7.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<PipelineRequest>): PipelineRequest {
    return PipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PipelineRequest>): PipelineRequest {
    const message = createBasePipelineRequest();
    message.pipelineId = object.pipelineId ?? '';
    message.name = object.name ?? '';
    message.stages =
      object.stages?.map((e) => PipelineStage.fromPartial(e)) || [];
    message.repository = object.repository ?? '';
    message.commitSha = object.commitSha ?? '';
    message.triggeredBy = object.triggeredBy ?? '';
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBasePipelineRequest_MetadataEntry(): PipelineRequest_MetadataEntry {
  return { key: '', value: '' };
}

export const PipelineRequest_MetadataEntry = {
  encode(
    message: PipelineRequest_MetadataEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): PipelineRequest_MetadataEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineRequest_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<PipelineRequest_MetadataEntry>,
  ): PipelineRequest_MetadataEntry {
    return PipelineRequest_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PipelineRequest_MetadataEntry>,
  ): PipelineRequest_MetadataEntry {
    const message = createBasePipelineRequest_MetadataEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBasePipelineStage(): PipelineStage {
  return {
    stageId: '',
    type: 0,
    name: '',
    workerCount: 0,
    dependsOn: [],
    config: {},
    image: '',
    command: [],
    args: [],
    timeoutSeconds: 0,
    retryPolicy: undefined,
  };
}

export const PipelineStage = {
  encode(
    message: PipelineStage,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.stageId !== '') {
      writer.uint32(10).string(message.stageId);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.name !== '') {
      writer.uint32(26).string(message.name);
    }
    if (message.workerCount !== 0) {
      writer.uint32(32).int32(message.workerCount);
    }
    for (const v of message.dependsOn) {
      writer.uint32(42).string(v!);
    }
    Object.entries(message.config).forEach(([key, value]) => {
      PipelineStage_ConfigEntry.encode(
        { key: key as any, value },
        writer.uint32(50).fork(),
      ).ldelim();
    });
    if (message.image !== '') {
      writer.uint32(58).string(message.image);
    }
    for (const v of message.command) {
      writer.uint32(66).string(v!);
    }
    for (const v of message.args) {
      writer.uint32(74).string(v!);
    }
    if (message.timeoutSeconds !== 0) {
      writer.uint32(80).int32(message.timeoutSeconds);
    }
    if (message.retryPolicy !== undefined) {
      RetryPolicy.encode(
        message.retryPolicy,
        writer.uint32(90).fork(),
      ).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): PipelineStage {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineStage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.stageId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.workerCount = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dependsOn.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = PipelineStage_ConfigEntry.decode(
            reader,
            reader.uint32(),
          );
          if (entry6.value !== undefined) {
            message.config[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.image = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.command.push(reader.string());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.args.push(reader.string());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.timeoutSeconds = reader.int32();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.retryPolicy = RetryPolicy.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<PipelineStage>): PipelineStage {
    return PipelineStage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PipelineStage>): PipelineStage {
    const message = createBasePipelineStage();
    message.stageId = object.stageId ?? '';
    message.type = object.type ?? 0;
    message.name = object.name ?? '';
    message.workerCount = object.workerCount ?? 0;
    message.dependsOn = object.dependsOn?.map((e) => e) || [];
    message.config = Object.entries(object.config ?? {}).reduce<{
      [key: string]: string;
    }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.image = object.image ?? '';
    message.command = object.command?.map((e) => e) || [];
    message.args = object.args?.map((e) => e) || [];
    message.timeoutSeconds = object.timeoutSeconds ?? 0;
    message.retryPolicy =
      object.retryPolicy !== undefined && object.retryPolicy !== null
        ? RetryPolicy.fromPartial(object.retryPolicy)
        : undefined;
    return message;
  },
};

function createBasePipelineStage_ConfigEntry(): PipelineStage_ConfigEntry {
  return { key: '', value: '' };
}

export const PipelineStage_ConfigEntry = {
  encode(
    message: PipelineStage_ConfigEntry,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.key !== '') {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== '') {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: _m0.Reader | Uint8Array,
    length?: number,
  ): PipelineStage_ConfigEntry {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineStage_ConfigEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(
    base?: DeepPartial<PipelineStage_ConfigEntry>,
  ): PipelineStage_ConfigEntry {
    return PipelineStage_ConfigEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PipelineStage_ConfigEntry>,
  ): PipelineStage_ConfigEntry {
    const message = createBasePipelineStage_ConfigEntry();
    message.key = object.key ?? '';
    message.value = object.value ?? '';
    return message;
  },
};

function createBaseRetryPolicy(): RetryPolicy {
  return { maxAttempts: 0, retryDelaySeconds: 0, retryableFailures: [] };
}

export const RetryPolicy = {
  encode(
    message: RetryPolicy,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.maxAttempts !== 0) {
      writer.uint32(8).int32(message.maxAttempts);
    }
    if (message.retryDelaySeconds !== 0) {
      writer.uint32(16).int32(message.retryDelaySeconds);
    }
    for (const v of message.retryableFailures) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): RetryPolicy {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRetryPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxAttempts = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.retryDelaySeconds = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.retryableFailures.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<RetryPolicy>): RetryPolicy {
    return RetryPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RetryPolicy>): RetryPolicy {
    const message = createBaseRetryPolicy();
    message.maxAttempts = object.maxAttempts ?? 0;
    message.retryDelaySeconds = object.retryDelaySeconds ?? 0;
    message.retryableFailures = object.retryableFailures?.map((e) => e) || [];
    return message;
  },
};

function createBasePipelineProgress(): PipelineProgress {
  return {
    pipelineId: '',
    stageId: '',
    status: 0,
    message: '',
    workerPodNames: [],
    progressPercentage: 0,
    timestamp: '',
    startedAt: '',
    completedAt: '',
    errorMessage: '',
    metrics: undefined,
  };
}

export const PipelineProgress = {
  encode(
    message: PipelineProgress,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.pipelineId !== '') {
      writer.uint32(10).string(message.pipelineId);
    }
    if (message.stageId !== '') {
      writer.uint32(18).string(message.stageId);
    }
    if (message.status !== 0) {
      writer.uint32(24).int32(message.status);
    }
    if (message.message !== '') {
      writer.uint32(34).string(message.message);
    }
    for (const v of message.workerPodNames) {
      writer.uint32(42).string(v!);
    }
    if (message.progressPercentage !== 0) {
      writer.uint32(48).int32(message.progressPercentage);
    }
    if (message.timestamp !== '') {
      writer.uint32(58).string(message.timestamp);
    }
    if (message.startedAt !== '') {
      writer.uint32(66).string(message.startedAt);
    }
    if (message.completedAt !== '') {
      writer.uint32(74).string(message.completedAt);
    }
    if (message.errorMessage !== '') {
      writer.uint32(82).string(message.errorMessage);
    }
    if (message.metrics !== undefined) {
      StageMetrics.encode(message.metrics, writer.uint32(90).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): PipelineProgress {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipelineId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.stageId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.message = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.workerPodNames.push(reader.string());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.progressPercentage = reader.int32();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.timestamp = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.startedAt = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.completedAt = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.metrics = StageMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<PipelineProgress>): PipelineProgress {
    return PipelineProgress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PipelineProgress>): PipelineProgress {
    const message = createBasePipelineProgress();
    message.pipelineId = object.pipelineId ?? '';
    message.stageId = object.stageId ?? '';
    message.status = object.status ?? 0;
    message.message = object.message ?? '';
    message.workerPodNames = object.workerPodNames?.map((e) => e) || [];
    message.progressPercentage = object.progressPercentage ?? 0;
    message.timestamp = object.timestamp ?? '';
    message.startedAt = object.startedAt ?? '';
    message.completedAt = object.completedAt ?? '';
    message.errorMessage = object.errorMessage ?? '';
    message.metrics =
      object.metrics !== undefined && object.metrics !== null
        ? StageMetrics.fromPartial(object.metrics)
        : undefined;
    return message;
  },
};

function createBaseStageMetrics(): StageMetrics {
  return {
    durationSeconds: 0,
    successfulWorkers: 0,
    failedWorkers: 0,
    totalWorkers: 0,
    avgCpuUsage: 0,
    avgMemoryMb: 0,
  };
}

export const StageMetrics = {
  encode(
    message: StageMetrics,
    writer: _m0.Writer = _m0.Writer.create(),
  ): _m0.Writer {
    if (message.durationSeconds !== 0) {
      writer.uint32(8).int32(message.durationSeconds);
    }
    if (message.successfulWorkers !== 0) {
      writer.uint32(16).int32(message.successfulWorkers);
    }
    if (message.failedWorkers !== 0) {
      writer.uint32(24).int32(message.failedWorkers);
    }
    if (message.totalWorkers !== 0) {
      writer.uint32(32).int32(message.totalWorkers);
    }
    if (message.avgCpuUsage !== 0) {
      writer.uint32(45).float(message.avgCpuUsage);
    }
    if (message.avgMemoryMb !== 0) {
      writer.uint32(53).float(message.avgMemoryMb);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): StageMetrics {
    const reader =
      input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStageMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.durationSeconds = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.successfulWorkers = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.failedWorkers = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.totalWorkers = reader.int32();
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.avgCpuUsage = reader.float();
          continue;
        case 6:
          if (tag !== 53) {
            break;
          }

          message.avgMemoryMb = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<StageMetrics>): StageMetrics {
    return StageMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StageMetrics>): StageMetrics {
    const message = createBaseStageMetrics();
    message.durationSeconds = object.durationSeconds ?? 0;
    message.successfulWorkers = object.successfulWorkers ?? 0;
    message.failedWorkers = object.failedWorkers ?? 0;
    message.totalWorkers = object.totalWorkers ?? 0;
    message.avgCpuUsage = object.avgCpuUsage ?? 0;
    message.avgMemoryMb = object.avgMemoryMb ?? 0;
    return message;
  },
};

/**
 * OttoscalerService - Otto-handler에서 Ottoscaler로의 스케일링 명령 서비스
 *
 * 🎯 목적:
 * - Otto-handler가 Ottoscaler에게 Worker Pod 스케일링 명령을 전송
 * - 스케일링 요청에 대한 동기적 응답 처리
 * - Worker Pod 상태 조회 기능
 *
 * 📊 통신 패턴:
 * 1. Otto-handler → ScaleUp/ScaleDown 호출 → Ottoscaler가 Worker Pod 처리
 * 2. Otto-handler → GetWorkerStatus 호출 → 현재 Worker 상태 반환
 */
export type OttoscalerServiceService = typeof OttoscalerServiceService;
export const OttoscalerServiceService = {
  /**
   * ScaleUp - Worker Pod를 생성하여 스케일 업
   *
   * 📝 동작 방식:
   * - Otto-handler가 새로운 CI/CD 작업 시작 시 호출
   * - Ottoscaler가 지정된 개수만큼 Worker Pod 생성
   * - 생성된 Worker Pod 정보를 응답으로 반환
   */
  scaleUp: {
    path: '/ottoscaler.v1.OttoscalerService/ScaleUp',
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ScaleRequest) =>
      Buffer.from(ScaleRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ScaleRequest.decode(value),
    responseSerialize: (value: ScaleResponse) =>
      Buffer.from(ScaleResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ScaleResponse.decode(value),
  },
  /**
   * ScaleDown - Worker Pod를 종료하여 스케일 다운
   *
   * 📝 동작 방식:
   * - Otto-handler가 CI/CD 작업 완료 또는 취소 시 호출
   * - Ottoscaler가 지정된 Worker Pod들을 정리
   */
  scaleDown: {
    path: '/ottoscaler.v1.OttoscalerService/ScaleDown',
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ScaleRequest) =>
      Buffer.from(ScaleRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ScaleRequest.decode(value),
    responseSerialize: (value: ScaleResponse) =>
      Buffer.from(ScaleResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ScaleResponse.decode(value),
  },
  /**
   * GetWorkerStatus - 현재 Worker Pod 상태 조회
   *
   * 📝 동작 방식:
   * - Otto-handler가 Worker 상태를 확인하고 싶을 때 호출
   * - 활성 상태인 Worker Pod 목록과 상태 정보 반환
   */
  getWorkerStatus: {
    path: '/ottoscaler.v1.OttoscalerService/GetWorkerStatus',
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: WorkerStatusRequest) =>
      Buffer.from(WorkerStatusRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => WorkerStatusRequest.decode(value),
    responseSerialize: (value: WorkerStatusResponse) =>
      Buffer.from(WorkerStatusResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => WorkerStatusResponse.decode(value),
  },
  /**
   * ExecutePipeline - CI/CD Pipeline 실행
   *
   * 📝 동작 방식:
   * - Otto-handler가 전체 Pipeline (build, test, deploy 등)을 전달
   * - Ottoscaler가 Stage 의존성을 파악하여 순차/병렬 실행
   * - 실시간 진행 상황을 스트리밍으로 반환
   */
  executePipeline: {
    path: '/ottoscaler.v1.OttoscalerService/ExecutePipeline',
    requestStream: false,
    responseStream: true,
    requestSerialize: (value: PipelineRequest) =>
      Buffer.from(PipelineRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => PipelineRequest.decode(value),
    responseSerialize: (value: PipelineProgress) =>
      Buffer.from(PipelineProgress.encode(value).finish()),
    responseDeserialize: (value: Buffer) => PipelineProgress.decode(value),
  },
} as const;

export interface OttoscalerServiceServer extends UntypedServiceImplementation {
  /**
   * ScaleUp - Worker Pod를 생성하여 스케일 업
   *
   * 📝 동작 방식:
   * - Otto-handler가 새로운 CI/CD 작업 시작 시 호출
   * - Ottoscaler가 지정된 개수만큼 Worker Pod 생성
   * - 생성된 Worker Pod 정보를 응답으로 반환
   */
  scaleUp: handleUnaryCall<ScaleRequest, ScaleResponse>;
  /**
   * ScaleDown - Worker Pod를 종료하여 스케일 다운
   *
   * 📝 동작 방식:
   * - Otto-handler가 CI/CD 작업 완료 또는 취소 시 호출
   * - Ottoscaler가 지정된 Worker Pod들을 정리
   */
  scaleDown: handleUnaryCall<ScaleRequest, ScaleResponse>;
  /**
   * GetWorkerStatus - 현재 Worker Pod 상태 조회
   *
   * 📝 동작 방식:
   * - Otto-handler가 Worker 상태를 확인하고 싶을 때 호출
   * - 활성 상태인 Worker Pod 목록과 상태 정보 반환
   */
  getWorkerStatus: handleUnaryCall<WorkerStatusRequest, WorkerStatusResponse>;
  /**
   * ExecutePipeline - CI/CD Pipeline 실행
   *
   * 📝 동작 방식:
   * - Otto-handler가 전체 Pipeline (build, test, deploy 등)을 전달
   * - Ottoscaler가 Stage 의존성을 파악하여 순차/병렬 실행
   * - 실시간 진행 상황을 스트리밍으로 반환
   */
  executePipeline: handleServerStreamingCall<PipelineRequest, PipelineProgress>;
}

export interface OttoscalerServiceClient extends Client {
  /**
   * ScaleUp - Worker Pod를 생성하여 스케일 업
   *
   * 📝 동작 방식:
   * - Otto-handler가 새로운 CI/CD 작업 시작 시 호출
   * - Ottoscaler가 지정된 개수만큼 Worker Pod 생성
   * - 생성된 Worker Pod 정보를 응답으로 반환
   */
  scaleUp(
    request: ScaleRequest,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  scaleUp(
    request: ScaleRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  scaleUp(
    request: ScaleRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  /**
   * ScaleDown - Worker Pod를 종료하여 스케일 다운
   *
   * 📝 동작 방식:
   * - Otto-handler가 CI/CD 작업 완료 또는 취소 시 호출
   * - Ottoscaler가 지정된 Worker Pod들을 정리
   */
  scaleDown(
    request: ScaleRequest,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  scaleDown(
    request: ScaleRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  scaleDown(
    request: ScaleRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ScaleResponse) => void,
  ): ClientUnaryCall;
  /**
   * GetWorkerStatus - 현재 Worker Pod 상태 조회
   *
   * 📝 동작 방식:
   * - Otto-handler가 Worker 상태를 확인하고 싶을 때 호출
   * - 활성 상태인 Worker Pod 목록과 상태 정보 반환
   */
  getWorkerStatus(
    request: WorkerStatusRequest,
    callback: (
      error: ServiceError | null,
      response: WorkerStatusResponse,
    ) => void,
  ): ClientUnaryCall;
  getWorkerStatus(
    request: WorkerStatusRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: WorkerStatusResponse,
    ) => void,
  ): ClientUnaryCall;
  getWorkerStatus(
    request: WorkerStatusRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: WorkerStatusResponse,
    ) => void,
  ): ClientUnaryCall;
  /**
   * ExecutePipeline - CI/CD Pipeline 실행
   *
   * 📝 동작 방식:
   * - Otto-handler가 전체 Pipeline (build, test, deploy 등)을 전달
   * - Ottoscaler가 Stage 의존성을 파악하여 순차/병렬 실행
   * - 실시간 진행 상황을 스트리밍으로 반환
   */
  executePipeline(
    request: PipelineRequest,
    options?: Partial<CallOptions>,
  ): ClientReadableStream<PipelineProgress>;
  executePipeline(
    request: PipelineRequest,
    metadata?: Metadata,
    options?: Partial<CallOptions>,
  ): ClientReadableStream<PipelineProgress>;
}

export const OttoscalerServiceClient = makeGenericClientConstructor(
  OttoscalerServiceService,
  'ottoscaler.v1.OttoscalerService',
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): OttoscalerServiceClient;
  service: typeof OttoscalerServiceService;
  serviceName: string;
};

/**
 * OttoHandlerLogService - Ottoscaler에서 Otto-handler로의 로그 전달 서비스
 *
 * 🎯 목적:
 * - Ottoscaler가 수집한 Worker Pod 로그를 Otto-handler로 전달
 * - Otto-handler에서 로그를 받아 웹 인터페이스에 표시
 * - 실시간 로그 스트리밍을 통한 CI/CD 작업 모니터링
 *
 * 📊 통신 패턴:
 * 1. Ottoscaler → ForwardWorkerLogs() 스트림으로 로그 전송
 * 2. Otto-handler → LogForwardResponse로 처리 상태 응답
 */
export type OttoHandlerLogServiceService = typeof OttoHandlerLogServiceService;
export const OttoHandlerLogServiceService = {
  /**
   * ForwardWorkerLogs - Worker Pod 로그를 Otto-handler로 전달
   *
   * 📝 동작 방식:
   * - Client (Ottoscaler): WorkerLogEntry를 지속적으로 전송
   * - Server (Otto-handler): LogForwardResponse로 처리 상태 응답
   *
   * 🔄 스트림 라이프사이클:
   * 1. Ottoscaler가 Worker Pod 로그 수집 시작
   * 2. 로그 발생 시마다 WorkerLogEntry 전송
   * 3. Otto-handler가 LogForwardResponse로 ACK/RETRY 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  forwardWorkerLogs: {
    path: '/ottoscaler.v1.OttoHandlerLogService/ForwardWorkerLogs',
    requestStream: true,
    responseStream: true,
    requestSerialize: (value: WorkerLogEntry) =>
      Buffer.from(WorkerLogEntry.encode(value).finish()),
    requestDeserialize: (value: Buffer) => WorkerLogEntry.decode(value),
    responseSerialize: (value: LogForwardResponse) =>
      Buffer.from(LogForwardResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => LogForwardResponse.decode(value),
  },
  /**
   * NotifyWorkerStatus - Worker Pod 상태 변경 알림
   *
   * 📝 동작 방식:
   * - Ottoscaler에서 Worker Pod 상태 변경 시 호출
   * - Otto-handler에서 상태를 받아 UI 업데이트
   */
  notifyWorkerStatus: {
    path: '/ottoscaler.v1.OttoHandlerLogService/NotifyWorkerStatus',
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: WorkerStatusNotification) =>
      Buffer.from(WorkerStatusNotification.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      WorkerStatusNotification.decode(value),
    responseSerialize: (value: WorkerStatusAck) =>
      Buffer.from(WorkerStatusAck.encode(value).finish()),
    responseDeserialize: (value: Buffer) => WorkerStatusAck.decode(value),
  },
} as const;

export interface OttoHandlerLogServiceServer
  extends UntypedServiceImplementation {
  /**
   * ForwardWorkerLogs - Worker Pod 로그를 Otto-handler로 전달
   *
   * 📝 동작 방식:
   * - Client (Ottoscaler): WorkerLogEntry를 지속적으로 전송
   * - Server (Otto-handler): LogForwardResponse로 처리 상태 응답
   *
   * 🔄 스트림 라이프사이클:
   * 1. Ottoscaler가 Worker Pod 로그 수집 시작
   * 2. 로그 발생 시마다 WorkerLogEntry 전송
   * 3. Otto-handler가 LogForwardResponse로 ACK/RETRY 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  forwardWorkerLogs: handleBidiStreamingCall<
    WorkerLogEntry,
    LogForwardResponse
  >;
  /**
   * NotifyWorkerStatus - Worker Pod 상태 변경 알림
   *
   * 📝 동작 방식:
   * - Ottoscaler에서 Worker Pod 상태 변경 시 호출
   * - Otto-handler에서 상태를 받아 UI 업데이트
   */
  notifyWorkerStatus: handleUnaryCall<
    WorkerStatusNotification,
    WorkerStatusAck
  >;
}

export interface OttoHandlerLogServiceClient extends Client {
  /**
   * ForwardWorkerLogs - Worker Pod 로그를 Otto-handler로 전달
   *
   * 📝 동작 방식:
   * - Client (Ottoscaler): WorkerLogEntry를 지속적으로 전송
   * - Server (Otto-handler): LogForwardResponse로 처리 상태 응답
   *
   * 🔄 스트림 라이프사이클:
   * 1. Ottoscaler가 Worker Pod 로그 수집 시작
   * 2. 로그 발생 시마다 WorkerLogEntry 전송
   * 3. Otto-handler가 LogForwardResponse로 ACK/RETRY 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  forwardWorkerLogs(): ClientDuplexStream<WorkerLogEntry, LogForwardResponse>;
  forwardWorkerLogs(
    options: Partial<CallOptions>,
  ): ClientDuplexStream<WorkerLogEntry, LogForwardResponse>;
  forwardWorkerLogs(
    metadata: Metadata,
    options?: Partial<CallOptions>,
  ): ClientDuplexStream<WorkerLogEntry, LogForwardResponse>;
  /**
   * NotifyWorkerStatus - Worker Pod 상태 변경 알림
   *
   * 📝 동작 방식:
   * - Ottoscaler에서 Worker Pod 상태 변경 시 호출
   * - Otto-handler에서 상태를 받아 UI 업데이트
   */
  notifyWorkerStatus(
    request: WorkerStatusNotification,
    callback: (error: ServiceError | null, response: WorkerStatusAck) => void,
  ): ClientUnaryCall;
  notifyWorkerStatus(
    request: WorkerStatusNotification,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: WorkerStatusAck) => void,
  ): ClientUnaryCall;
  notifyWorkerStatus(
    request: WorkerStatusNotification,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: WorkerStatusAck) => void,
  ): ClientUnaryCall;
}

export const OttoHandlerLogServiceClient = makeGenericClientConstructor(
  OttoHandlerLogServiceService,
  'ottoscaler.v1.OttoHandlerLogService',
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): OttoHandlerLogServiceClient;
  service: typeof OttoHandlerLogServiceService;
  serviceName: string;
};

export type LogStreamingServiceService = typeof LogStreamingServiceService;
export const LogStreamingServiceService = {
  /**
   * StreamLogs - 양방향 스트리밍 RPC로 로그 전송
   *
   * 📝 동작 방식:
   * - Client (Worker Pod): LogEntry 메시지를 지속적으로 전송
   * - Server (NestJS): LogResponse로 처리 상태 응답
   * - 연결이 끊어지면 자동으로 재연결 시도
   *
   * 🔄 스트림 라이프사이클:
   * 1. Worker Pod가 스트림 연결 시작
   * 2. 로그 발생 시마다 LogEntry 전송
   * 3. 서버가 LogResponse로 ACK/RETRY/DROP 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  streamLogs: {
    path: '/ottoscaler.v1.LogStreamingService/StreamLogs',
    requestStream: true,
    responseStream: true,
    requestSerialize: (value: LogEntry) =>
      Buffer.from(LogEntry.encode(value).finish()),
    requestDeserialize: (value: Buffer) => LogEntry.decode(value),
    responseSerialize: (value: LogResponse) =>
      Buffer.from(LogResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => LogResponse.decode(value),
  },
  /**
   * RegisterWorker - Worker Pod 시작 시 서버에 등록
   *
   * 📋 등록 프로세스:
   * 1. Worker Pod가 시작되면 즉시 호출
   * 2. Worker 메타데이터와 작업 정보 전송
   * 3. 서버에서 세션 ID와 로깅 설정 반환
   * 4. 이후 StreamLogs에서 세션 ID 사용
   */
  registerWorker: {
    path: '/ottoscaler.v1.LogStreamingService/RegisterWorker',
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: WorkerRegistration) =>
      Buffer.from(WorkerRegistration.encode(value).finish()),
    requestDeserialize: (value: Buffer) => WorkerRegistration.decode(value),
    responseSerialize: (value: RegistrationResponse) =>
      Buffer.from(RegistrationResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => RegistrationResponse.decode(value),
  },
} as const;

export interface LogStreamingServiceServer
  extends UntypedServiceImplementation {
  /**
   * StreamLogs - 양방향 스트리밍 RPC로 로그 전송
   *
   * 📝 동작 방식:
   * - Client (Worker Pod): LogEntry 메시지를 지속적으로 전송
   * - Server (NestJS): LogResponse로 처리 상태 응답
   * - 연결이 끊어지면 자동으로 재연결 시도
   *
   * 🔄 스트림 라이프사이클:
   * 1. Worker Pod가 스트림 연결 시작
   * 2. 로그 발생 시마다 LogEntry 전송
   * 3. 서버가 LogResponse로 ACK/RETRY/DROP 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  streamLogs: handleBidiStreamingCall<LogEntry, LogResponse>;
  /**
   * RegisterWorker - Worker Pod 시작 시 서버에 등록
   *
   * 📋 등록 프로세스:
   * 1. Worker Pod가 시작되면 즉시 호출
   * 2. Worker 메타데이터와 작업 정보 전송
   * 3. 서버에서 세션 ID와 로깅 설정 반환
   * 4. 이후 StreamLogs에서 세션 ID 사용
   */
  registerWorker: handleUnaryCall<WorkerRegistration, RegistrationResponse>;
}

export interface LogStreamingServiceClient extends Client {
  /**
   * StreamLogs - 양방향 스트리밍 RPC로 로그 전송
   *
   * 📝 동작 방식:
   * - Client (Worker Pod): LogEntry 메시지를 지속적으로 전송
   * - Server (NestJS): LogResponse로 처리 상태 응답
   * - 연결이 끊어지면 자동으로 재연결 시도
   *
   * 🔄 스트림 라이프사이클:
   * 1. Worker Pod가 스트림 연결 시작
   * 2. 로그 발생 시마다 LogEntry 전송
   * 3. 서버가 LogResponse로 ACK/RETRY/DROP 응답
   * 4. Worker 작업 완료 시 스트림 종료
   */
  streamLogs(): ClientDuplexStream<LogEntry, LogResponse>;
  streamLogs(
    options: Partial<CallOptions>,
  ): ClientDuplexStream<LogEntry, LogResponse>;
  streamLogs(
    metadata: Metadata,
    options?: Partial<CallOptions>,
  ): ClientDuplexStream<LogEntry, LogResponse>;
  /**
   * RegisterWorker - Worker Pod 시작 시 서버에 등록
   *
   * 📋 등록 프로세스:
   * 1. Worker Pod가 시작되면 즉시 호출
   * 2. Worker 메타데이터와 작업 정보 전송
   * 3. 서버에서 세션 ID와 로깅 설정 반환
   * 4. 이후 StreamLogs에서 세션 ID 사용
   */
  registerWorker(
    request: WorkerRegistration,
    callback: (
      error: ServiceError | null,
      response: RegistrationResponse,
    ) => void,
  ): ClientUnaryCall;
  registerWorker(
    request: WorkerRegistration,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: RegistrationResponse,
    ) => void,
  ): ClientUnaryCall;
  registerWorker(
    request: WorkerRegistration,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: RegistrationResponse,
    ) => void,
  ): ClientUnaryCall;
}

export const LogStreamingServiceClient = makeGenericClientConstructor(
  LogStreamingServiceService,
  'ottoscaler.v1.LogStreamingService',
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): LogStreamingServiceClient;
  service: typeof LogStreamingServiceService;
  serviceName: string;
};

type Builtin =
  | Date
  | Function
  | Uint8Array
  | string
  | number
  | boolean
  | undefined;

export type DeepPartial<T> = T extends Builtin
  ? T
  : T extends globalThis.Array<infer U>
    ? globalThis.Array<DeepPartial<U>>
    : T extends ReadonlyArray<infer U>
      ? ReadonlyArray<DeepPartial<U>>
      : T extends { $case: string }
        ? { [K in keyof Omit<T, '$case'>]?: DeepPartial<T[K]> } & {
            $case: T['$case'];
          }
        : T extends {}
          ? { [K in keyof T]?: DeepPartial<T[K]> }
          : Partial<T>;

function longToNumber(long: Long): number {
  if (long.gt(globalThis.Number.MAX_SAFE_INTEGER)) {
    throw new globalThis.Error('Value is larger than Number.MAX_SAFE_INTEGER');
  }
  if (long.lt(globalThis.Number.MIN_SAFE_INTEGER)) {
    throw new globalThis.Error('Value is smaller than Number.MIN_SAFE_INTEGER');
  }
  return long.toNumber();
}

if (_m0.util.Long !== Long) {
  _m0.util.Long = Long as any;
  _m0.configure();
}
